{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxaU8Buh5NWS"
   },
   "source": [
    "# **Potential Public Solutions**\n",
    "The following is a summary of research papers/articles (with links) that focus on classifying spam emails. Since my dataset contains both the [SpamAssassin](https://spamassassin.apache.org/old/publiccorpus/) and [Enron Spam](https://www2.aueb.gr/users/ion/data/enron-spam/) datasets, this section will be split into two parts, each corresponding with one of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm60FF-w5XK6"
   },
   "source": [
    "### **Solution with the SpamAssassin dataset:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_2SycNB8Xbj"
   },
   "source": [
    "#### **\"[Email Spam Classification](https://medium.com/@yesprabhakaran98/email-spam-classification-92b661d3b700)\"** by prabhakran98  (via medium.com):\n",
    "\n",
    "***Dataset***:\n",
    "- [SpamAssassin dataset](https://spamassassin.apache.org/old/publiccorpus/)\n",
    "\n",
    "***Data Preprocessing***:\n",
    "- Perform **TF-IDF** on the text corpus  \n",
    "  >TF-IDF is an algorithm that uses the frequency of words to determine how relevant those words are to a given document.\n",
    "  \n",
    "***Model Training Techniques & Evaluation***:\n",
    "\n",
    "| Model                     | Accuracy    | F 0.5 Score\n",
    "| :-----------------------: | :---------: | :----------:\n",
    "| **Random Forest**         | 0.98        | 0.98\n",
    "| **XGBoost**               | 0.97        | 0.96\n",
    "| **Decision Tree**         | 0.93        | 0.93\n",
    "| **Logistic Regression**   | 0.93        | 0.93\n",
    "| **Naive Bayes**           | 0.89        | 0.90\n",
    "| **KNN**                   | 0.67        | 0.54\n",
    "\n",
    "  >Notes:\n",
    "  - All models included hyperparameter tuning using a grid search\n",
    "  - F 0.5 Score is used as a metric (rather than F1 score) since the SpamAssassin dataset is imbalanced\n",
    "\n",
    "  ***Conclusion***:  \n",
    "  Ensemble Models perform better, especially the **Random Forest model**, as it had the highest accuracy and F 0.5 score.   \n",
    "  However, all models acheive a 90+ score except for K Nearest Neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXWAGElF5kUF"
   },
   "source": [
    "### **Solution with the Enron Spam dataset:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-cU9lUh6I-p"
   },
   "source": [
    "#### **\"[Empirical Analysis on Email Classification Using the Enron Dataset](https://towardsdatascience.com/empirical-analysis-on-email-classification-using-the-enron-dataset-19054d558697)\"** by Suleka Helmini  (via towardsdatascience.com):\n",
    "- [Github Code Link](https://github.com/suleka96/Email-Classification)\n",
    "\n",
    "***Dataset***:\n",
    "- [Enron Spam dataset](https://www2.aueb.gr/users/ion/data/enron-spam/)\n",
    "\n",
    "***Data Preprocessing***:  \n",
    "For the ML models:  \n",
    "- Utilize a **bag-of-words** approach:  \n",
    "> First, make a dictionary of the 3000 most common words in the corpus. Then iterate through the eamils and record the occurence frequency of each token in the email corresponding to the token in the dictionary.\n",
    "\n",
    "For the DL model (i.e. the Recurrent Neural Network):\n",
    "- Utilize a slightly different **bag-of-words** approach:  \n",
    "> First, create a dictionary of all the words in the corpus and index them starting from 1. Then iterate through the emails, and map each word to the corresponding index in the dictionary (this ensures the sequence of words is retained). Finally, to ensure all the emails have the same length, pad all the emails to the length of the longest email by adding 0's to the beginning of each sequence.\n",
    "\n",
    "***Model Training Techniques & Evaluation***:\n",
    "\n",
    "| ML Model                          | Accuracy | F1 Score| Recall|Precision     \n",
    "| :-------------------------------: | :-------:| :-----: | :----:| :------:\n",
    "| **Logistic Regression**           | 0.973    | 0.969   | 0.972 | 0.966\n",
    "| **Random Forest Classifier**      | 0.971    | 0.966   | 0.969 | 0.964\n",
    "| **Support Vector Classification** | 0.958    | 0.952   | 0.962 | 0.943\n",
    "\n",
    "\n",
    "> Notes:\n",
    "  - All ML models included manual hyperparameter tuning\n",
    "\n",
    "| DL Model                             | Accuracy  | F1 Score| Recall|Precision\n",
    "| :----------------------------------: | :-------: | :-----: | :----:| :------:\n",
    "| **Recurrent Neural Network (LSTM)**  | 0.981     | 0.980   | 0.980 | 0.981\n",
    "> Notes:\n",
    "  - Cost function: softmax cross entropy with logits\n",
    "  - Optimization function: Adam optimizer\n",
    "  - Activation function: sigmoid\n",
    "\n",
    "  ***Conclusion***:  \n",
    "  Logistic Regression outperformed all of the ML Models, but the **LSTM model** outperformed the logistic regression algorithm because of its ability to model long term dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1pH9g7y50EI"
   },
   "source": [
    "# **Reproduction of Available Solutions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "leggU7UfSo33",
    "outputId": "f0602ca2-5949-44ae-d92b-0443f825ddb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JkS-f2RkSBwC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6TCBHK4OStJs"
   },
   "outputs": [],
   "source": [
    "# Load clean data into a pandas dataframe\n",
    "DATA_PATH = \"/content/drive/My Drive/UCSD Machine Learning Engineering Bootcamp/Capstone Project/\"\n",
    "df = pd.read_csv(DATA_PATH + 'CleanData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SERlwOXUOlgS"
   },
   "source": [
    "### **Reproduction of SpamAssassin dataset Solution:**\n",
    "(TF-IDF for the preprocessing, and a Random Forest model for the training)\n",
    "\n",
    "****NOTE**: the article did not have a link to the code, so I had to code it myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-oohnoj_aCdE"
   },
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_7L2TfZibLi"
   },
   "source": [
    "#### Step 1: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5bqWw0FuPv4-"
   },
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize the tfidf vectorizer\n",
    "tfidf_vec = TfidfVectorizer(max_features=10000)\n",
    "# convert Clean_Text to numbers with TfidfVectorizer\n",
    "tfidf = tfidf_vec.fit_transform(df1['Clean_Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yRL27NDUZU_",
    "outputId": "a955406b-3b69-4e16-a0b3-433d6adfed26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39763, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the tfidf data features to array\n",
    "tfidf = tfidf.toarray()\n",
    "# show shape of the feature vector\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDYJ_nh6if9y"
   },
   "source": [
    "#### Step 2: Preliminary Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ut2M7nNMcTNm"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing set\n",
    "X_idf = tfidf\n",
    "y = df1.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_idf, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "mqJAjL5Xt8V1",
    "outputId": "21c6b7b5-8abe-4d8a-c85d-141dc9b8c616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      6245\n",
      "         1.0       0.97      0.99      0.98      5684\n",
      "\n",
      "    accuracy                           0.98     11929\n",
      "   macro avg       0.98      0.98      0.98     11929\n",
      "weighted avg       0.98      0.98      0.98     11929\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest: initial fitting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the random forest classifier to the data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Generate Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRUxb3KICF9h",
    "outputId": "17e5ecc3-fbae-4d41-9577-90a8e1e72ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at parameters used by our current random forest\n",
    "rf_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LBfkyPNCQIP"
   },
   "source": [
    "#### Step 3: Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3Nh5aPVe40T",
    "outputId": "5b56c84b-e1f8-4a5f-8851-8da0ae1a5195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY4mWFV9Cr_m",
    "outputId": "cd6321fd-b520-45f5-892e-3912b0bf01b0"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=0.974 total time=49.6min\n",
      "[CV 2/3] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=0.975 total time=49.8min\n",
      "[CV 3/3] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=0.974 total time=49.1min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=600;, score=0.968 total time=12.9min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=600;, score=0.970 total time=12.9min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=600;, score=0.970 total time=12.9min\n",
      "[CV 1/3] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.977 total time=48.9min\n",
      "[CV 2/3] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.978 total time=49.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.977 total time=48.6min\n",
      "[CV 1/3] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=0.976 total time=52.9min\n",
      "[CV 2/3] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=0.976 total time=53.1min\n",
      "[CV 3/3] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=2000;, score=0.975 total time=52.9min\n",
      "[CV 1/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1400;, score=0.977 total time=36.3min\n",
      "[CV 2/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1400;, score=0.977 total time=36.2min\n",
      "[CV 3/3] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1400;, score=0.976 total time=36.4min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.940 total time= 1.7min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.944 total time= 1.7min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.950 total time= 1.7min\n",
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800;, score=0.943 total time= 4.7min\n",
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800;, score=0.942 total time= 4.7min\n",
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=800;, score=0.951 total time= 4.7min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000;, score=0.976 total time=15.0min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000;, score=0.977 total time=15.2min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000;, score=0.975 total time=15.0min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1200;, score=0.975 total time=28.3min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1200;, score=0.977 total time=27.8min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1200;, score=0.974 total time=27.4min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=0.973 total time=20.6min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=0.974 total time=20.5min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=0.972 total time=20.7min\n",
      "[CV 1/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.961 total time= 6.7min\n",
      "[CV 2/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.961 total time= 6.5min\n",
      "[CV 3/3] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.963 total time= 6.5min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1600;, score=0.945 total time= 9.3min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1600;, score=0.945 total time= 9.2min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1600;, score=0.950 total time= 9.2min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1200;, score=0.973 total time=25.3min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1200;, score=0.975 total time=24.9min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1200;, score=0.973 total time=24.9min\n",
      "[CV 1/3] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=0.963 total time=13.9min\n",
      "[CV 2/3] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=0.961 total time=13.7min\n",
      "[CV 3/3] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=0.965 total time=13.5min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200;, score=0.966 total time=12.6min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200;, score=0.967 total time=12.7min\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END bootstrap=True, max_depth=60, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200;, score=0.967 total time=12.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END bootstrap=False, max_depth=None, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=0.975 total time=22.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Use random search to find the best hyperparameters, using 3 fold cross validation\n",
    "# across 100 different combinations\n",
    "grid_search = RandomizedSearchCV(rf,\n",
    "                                 param_distributions = random_grid,\n",
    "                                 n_iter=20,\n",
    "                                 cv=3,\n",
    "                                 verbose=3)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aci1VRWR7Qxb"
   },
   "source": [
    "Unfortunately the above Randomized Grid Search did not complete after 24+ hours of runtime, and none of its random models acheived a higher score than the preliminary model (with default hyperparameters) in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxBbEVRb9AvU"
   },
   "source": [
    "#### Random Forest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x87am0TCA7Is",
    "outputId": "9fc555f4-8898-4178-9384-b98907f8af39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "Test accuracy: 0.981\n",
      "F1 Score: 0.981\n",
      "Recall: 0.982\n",
      "Precision: 0.981\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model metrics\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(\"Test accuracy: {:.3f}\".format(accuracy))\n",
    "print(\"F1 Score: {:.3f}\".format(f1))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"Precision: {:.3f}\".format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98lQzp2_A7dQ"
   },
   "source": [
    "My **Random Forest model acheived an accuracy, f1 score, and precision of 0.981, and a recall of 0.982**. This model's performance is roughly identical to the performance of the Random Forest model used in the article for the SpamAssassin dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oucUdmHOqgU"
   },
   "source": [
    "### Reproduction of Enron Spam dataset Solution:\n",
    "(Bag of words for the preprocessing, and a LSTM model for the training)\n",
    "\n",
    "****NOTE**: the article did have a [Github link](https://github.com/suleka96/Email-Classification/blob/master/Enron_LSTM.py) to the code, so I just copy and pasted it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y-JGcR-T48mJ"
   },
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (23.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1\n",
      "    Uninstalling pip-23.1:\n",
      "      Successfully uninstalled pip-23.1\n",
      "Successfully installed pip-23.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/anastasiaarsky/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x30Ardwc7p0S"
   },
   "outputs": [],
   "source": [
    "# method to get data with the same batch size\n",
    "def get_batches(x, y, batch_size=100):\n",
    "    n_batches = len(x) // batch_size\n",
    "    x, y = x[:n_batches * batch_size], y[:n_batches * batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii + batch_size], y[ii:ii + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5w3zvGl7t3J"
   },
   "outputs": [],
   "source": [
    "# train and test the LSTM model\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def train_test(df):\n",
    "    start = time.time()\n",
    "\n",
    "    # -----------------Train/Validation/Test Split------------------------------\n",
    "    start_split = time.time()\n",
    "\n",
    "    # set features and labels\n",
    "    features = df.Clean_Text\n",
    "    labels = df.Label\n",
    "\n",
    "    split_frac1 = 0.8\n",
    "\n",
    "    idx1 = int(len(features) * split_frac1)\n",
    "    train_x, val_x = features[:idx1], features[idx1:]\n",
    "    train_y, val_y = labels[:idx1], labels[idx1:]\n",
    "\n",
    "    split_frac2 = 0.5\n",
    "\n",
    "    idx2 = int(len(val_x) * split_frac2)\n",
    "    val_x, test_x = val_x[:idx2], val_x[idx2:]\n",
    "    val_y, test_y = val_y[:idx2], val_y[idx2:]\n",
    "\n",
    "    print(\"-----------------Train/Validation/Test Split-----------------\\n\")\n",
    "    print(\"\\nFeature Shapes:\")\n",
    "    print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
    "          \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "          \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
    "\n",
    "    print(\"\\nLabel Shapes:\")\n",
    "    print(\"Train set: \\t\\t{}\".format(train_y.shape),\n",
    "          \"\\nValidation set: \\t{}\".format(val_y.shape),\n",
    "          \"\\nTest set: \\t\\t{}\".format(test_y.shape))\n",
    "    \n",
    "    end_split = time.time()\n",
    "    print(\"\\nTime Elapsed: \\t\\t{}\\n\".format(end_split - start_split))\n",
    "\n",
    "    # -----------------Initialize Values----------------------------------------\n",
    "\n",
    "    start_initialize = time.time()\n",
    "\n",
    "    # set LSTM variables\n",
    "    epochs = 15\n",
    "    lstm_layers = 1\n",
    "    batch_size = 179\n",
    "    lstm_size = 30\n",
    "    learning_rate = 0.003\n",
    "\n",
    "    # set number of unique words\n",
    "    #n_words = 1 + len(\n",
    "    #    list(df['Clean_Text'].str.split(' ', expand=True).stack().unique()))\n",
    "\n",
    "    unique_words = Counter()\n",
    "    df['Clean_Text'].apply(lambda x: unique_words.update(x.split()))\n",
    "    n_words = len(unique_words)\n",
    "\n",
    "    print(\"\\n---------------Initialized Values--------------------------\\n\")\n",
    "    print(\"Number of unique words: \\t\\t{}\".format(n_words),\n",
    "          \"\\nLSTM size: \\t\\t{}\".format(lstm_size),\n",
    "          \"\\nLSTM layers: \\t\\t{}\".format(lstm_layers),\n",
    "          \"\\nBatch size: \\t\\t{}\".format(batch_size),\n",
    "          \"\\nEpochs: \\t\\t{}\".format(epochs),\n",
    "          \"\\nLearning Rate \\t\\t{}\".format(learning_rate))\n",
    "    \n",
    "    end_initialize = time.time()\n",
    "    print(\"\\nTime Elapsed: \\t\\t{}\\n\".format(end_initialize - start_initialize))\n",
    "\n",
    "    # -----------------Placeholders---------------------------------------------\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "        tf.set_random_seed(1)\n",
    "\n",
    "        inputs_ = tf.placeholder(tf.int32, [None, None], name=\"inputs\")\n",
    "        labels_ = tf.placeholder(tf.float32, [None, None], name=\"labels\")\n",
    "\n",
    "        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "        embed_size = 300\n",
    "\n",
    "        embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "        embed = tf.nn.embedding_lookup(embedding, inputs_)\n",
    "        print(embedding.shape)\n",
    "        print(embed.shape)\n",
    "\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "\n",
    "        initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                                 initial_state=initial_state)\n",
    "\n",
    "        hidden1 = tf.layers.dense(outputs[:, -1], units=25, activation=tf.nn.relu)\n",
    "\n",
    "        hidden2 = tf.layers.dense(hidden1, units=15, activation=tf.nn.relu)\n",
    "\n",
    "        logit = tf.contrib.layers.fully_connected(hidden2, num_outputs=1,\n",
    "                                                  activation_fn=None)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logit, labels=labels_))\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "        predictions = tf.round(tf.nn.sigmoid(logit))\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    # -----------------Training-------------------------------------------------\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        print(\"Starting Training...\")\n",
    "        tf.set_random_seed(1)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        iteration = 1\n",
    "        for e in range(epochs):\n",
    "            start_train = time.time()\n",
    "            state = sess.run(initial_state)\n",
    "            for ii, (x, y) in enumerate(get_batches(np.array(train_x),\n",
    "                                            np.array(train_y), batch_size), 1):\n",
    "\n",
    "                feed = {inputs_: x,\n",
    "                        labels_: y[:, None],\n",
    "                        keep_prob: 0.5,\n",
    "                        initial_state: state}\n",
    "                loss, states, _ = sess.run([cost, final_state, optimizer],\n",
    "                                           feed_dict=feed)\n",
    "\n",
    "                if iteration % 5 == 0:\n",
    "                    print(\"\\nEpoch: {}/{}\".format(e, epochs),\n",
    "                          \"Iteration: {}\".format(iteration),\n",
    "                          \"Train loss: {:.3f}\".format(loss),\n",
    "                          \"\\nTime Elapsed: \\t\\t{}\".format(time.time() - start_train))\n",
    "                iteration += 1\n",
    "\n",
    "        saver.save(sess, \"checkpoints/sentiment.ckpt\")\n",
    "\n",
    "    # -----------------Testing Validation Set-----------------------------------\n",
    "    print(\"Starting Validation Set...\")\n",
    "\n",
    "    start_validation = time.time()\n",
    "\n",
    "    prediction_vals = []\n",
    "    y_vals = []\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        tf.set_random_seed(1)\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "\n",
    "        test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "\n",
    "        for ii, (x, y) in enumerate(get_batches(np.array(val_x), np.array(val_y),\n",
    "                                                batch_size), 1):\n",
    "\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 1,\n",
    "                    initial_state: test_state}\n",
    "\n",
    "            prediction = sess.run(predictions, feed_dict=feed)\n",
    "            prediction = prediction.astype(int)\n",
    "\n",
    "            for i in range(len(prediction)):\n",
    "                prediction_vals.append(prediction[i][0])\n",
    "                y_vals.append(y[i])\n",
    "\n",
    "        accuracy = accuracy_score(y_vals, prediction_vals)\n",
    "        f1 = f1_score(y_vals, prediction_vals, average='macro')\n",
    "        recall = recall_score(y_true=y_vals, y_pred=prediction_vals, average='macro')\n",
    "        precision = precision_score(y_vals, prediction_vals, average='macro')\n",
    "\n",
    "        print(\"-----------------Testing Validation Set------------------\")\n",
    "        print(\"Test accuracy: {:.3f}\".format(accuracy))\n",
    "        print(\"F1 Score: {:.3f}\".format(f1))\n",
    "        print(\"Recall: {:.3f}\".format(recall))\n",
    "        print(\"Precision: {:.3f}\".format(precision))\n",
    "\n",
    "        end_validation = time.time()\n",
    "        print(\"\\nTime Elapsed: \\t\\t{}\\n\".format(end_validation - start_validation))\n",
    "\n",
    "\n",
    "    # -----------------Testing Test Set-----------------------------------------\n",
    "    print(\"Starting Testing Set...\")\n",
    "\n",
    "    start_test = time.time()\n",
    "\n",
    "    prediction_val = []\n",
    "    y_val = []\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        tf.set_random_seed(1)\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "        test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "\n",
    "        for ii, (x, y) in enumerate(get_batches(np.array(test_x),\n",
    "                                                np.array(test_y), batch_size), 1):\n",
    "\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 1,\n",
    "                    initial_state: test_state}\n",
    "\n",
    "            prediction = sess.run(predictions, feed_dict=feed)\n",
    "            prediction = prediction.astype(int)\n",
    "\n",
    "            for i in range(len(prediction)):\n",
    "                prediction_val.append(prediction[i][0])\n",
    "                y_val.append(y[i])\n",
    "\n",
    "        accuracy = accuracy_score(y_val, prediction_val)\n",
    "        f1 = f1_score(y_val, prediction_val, average='macro')\n",
    "        recall = recall_score(y_true=y_val, y_pred=prediction_val, average='macro')\n",
    "        precision = precision_score(y_val, prediction_val, average='macro')\n",
    "\n",
    "        print(\"-----------------Testing Test Set------------------------\")\n",
    "        print(\"Test accuracy: {:.3f}\".format(accuracy))\n",
    "        print(\"F1 Score: {:.3f}\".format(f1))\n",
    "        print(\"Recall: {:.3f}\".format(recall))\n",
    "        print(\"Precision: {:.3f}\".format(precision))\n",
    "\n",
    "        end_test = time.time()\n",
    "        print(\"\\nTime Elapsed: \\t\\t{}\\n\".format(end_test - start_test))\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"\\nTotal Time Elapsed: \\t\\t{}\\n\".format(end - start))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Jzqhuxd_jZw",
    "outputId": "b425dd61-437a-40ed-c41f-1ecfd949c091"
   },
   "outputs": [],
   "source": [
    "train_test(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyA-YGqfrlYb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tap0bj9VrliF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHCb6Euyrlrc"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR7eoGoOrl0D"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-uDtANuj3LN"
   },
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hmg5fteuknXh"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing set\n",
    "X = df2.Clean_Text\n",
    "y = df2.Label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47ZcEqnVnPRj"
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "num_words=10000\n",
    "maxlen=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1EquCnoj5AH"
   },
   "outputs": [],
   "source": [
    "# Vectorize the text samples into a 2D integer tensor\n",
    "# if tokenizer doesnt work --> https://www.tensorflow.org/tutorials/load_data/text\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, char_level=False)\n",
    "\n",
    "# updates an internal vocabulary based on X_train\n",
    "# (required before texts_to_sequences)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Transform X_train and X_test to a sequence of integers.\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "len(sequences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUGU42H5ldCH"
   },
   "outputs": [],
   "source": [
    "# Pad sequences with 0s so that they are all the same length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "print('Shape of data tensor:', X_train.shape)\n",
    "print('Shape of data test tensor:', X_test.shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srnot3pDnVzd"
   },
   "source": [
    "#### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_lje6RMnb_k"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "backend.clear_session()\n",
    "\n",
    "# set the seed for random number generators\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31mObrxEnmRH"
   },
   "outputs": [],
   "source": [
    "def create_model(maxlen,num_words,num_categories):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(num_words,output_dim=100,input_length=maxlen,trainable=True))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_categories, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UqtO-4tnuch"
   },
   "outputs": [],
   "source": [
    "print('===============Create The Model==========================')\n",
    "# We get to choose embedding dimensionality\n",
    "D = 100\n",
    "# Hidden state dimentionality\n",
    "M = 64\n",
    "V = len(tokenizer.word_index)\n",
    "T = data_train.shape[1]\n",
    "\n",
    "# model.add(embedding)\n",
    "# model.add(SpatialDropout1D(0.2))\n",
    "# model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V + 1, D)(i)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = LSTM(M, return_sequences=True, activation='relu')(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "# Compile and fit\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print('Training model...........')\n",
    "r = model.fit(data_train, y_train, epochs=15,\n",
    "              validation_data=(data_test, y_test),\n",
    "              batch_size=1)\n",
    "\n",
    "print('================Model Evaluation=====================')\n",
    "evaluate(model, data_train, data_test, y_train, y_test)\n",
    "plot_loss_evaluation(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-s_HyH5I7936"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZliV2QFI57dl"
   },
   "source": [
    "# **Analysis and Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pL__3B66Ek6"
   },
   "source": [
    "### **Results**:\n",
    "| Model                             | Accuracy | F1 Score| Recall|Precision     \n",
    "| :-------------------------------:  | :-------:| :-----: | :----:| :------:\n",
    "| **Random Forest**                  | 0.981    | 0.981   | 0.981 | 0.982\n",
    "| **Recurrent Neural Network (LSTM)**| 0.973    | 0.969   | 0.972 | 0.966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q70YKp8U_iio"
   },
   "source": [
    "#### **Analysis**\n",
    "Considering the obtained results, the ___ model outperformed the ____ model. However, both models achieved a ___ accuracy rate, which is not bad. Moving forward, I will most likely be utilizing a slighlty more complicated deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2sHoH1k_h15"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
